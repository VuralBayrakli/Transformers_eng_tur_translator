{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d101719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from collections import Counter \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994aa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73070a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    '''\n",
    "    Prepare English and French examples for batch-friendly modeling by appending\n",
    "    BOS/EOS tokens to each, stacking the tensors, and filling trailing spaces of\n",
    "    shorter sentences with the <pad> token. To be used as the collate_fn in the\n",
    "    English-to-Turkish DataLoader.\n",
    "\n",
    "    Input: \n",
    "    - data_batch, an iterable of (English, Turkish) tuples from the datasets \n",
    "      created above\n",
    "\n",
    "    Outputs\n",
    "    - en_batch: a (max length X batch size) tensor of English token IDs\n",
    "    - tr_batch: a (max length X batch size) tensor of Turkish token IDs \n",
    "    '''\n",
    "    en_batch, tr_batch = [], []\n",
    "    for (en_item, tr_item) in data_batch:\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        tr_batch.append(torch.cat([torch.tensor([BOS_IDX]), tr_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "    tr_batch = pad_sequence(tr_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "\n",
    "    return en_batch, tr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fb4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Değişkeni geri yükleme\n",
    "with open('en_vocab.pkl', 'rb') as f:\n",
    "    en_vocab = pickle.load(f)\n",
    "    \n",
    "with open('tr_vocab.pkl', 'rb') as f:\n",
    "    tr_vocab = pickle.load(f)\n",
    "    \n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']\n",
    "\n",
    "SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for en_id, tr_id in zip(en_vocab.lookup_indices(SPECIALS), tr_vocab.lookup_indices(SPECIALS)):\n",
    "    assert en_id == tr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49841db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: <bos> excessive alcohol consumption can harm the liver . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "French: <bos> aşırı alkol tüketimi karaciğere zarar verebilir . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "English: <bos> paris is a famous destination with a romantic atmosphere for couples . <eos> <pad> <pad> <pad> <pad>\n",
      "French: <bos> paris , çiftler için romantik bir atmosfere sahip ünlü bir destinasyondur . <eos> <pad> <pad>\n",
      "\n",
      "English: <bos> i felt a deep sense of embarrassment when i tripped and fell in front of everyone . <eos>\n",
      "French: <bos> herkesin önünde tökezleyip düştüğümde derin bir utanma hissi hissettim . <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "English: <bos> the researchers were able to derive meaningful conclusions from the data . <eos> <pad> <pad> <pad> <pad>\n",
      "French: <bos> araştırmacılar , veriden anlamlı sonuçlar çıkarmayı başardı . <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "English: <bos> the artist was in the process of making a sculpture from marble . <eos> <pad> <pad>\n",
      "French: <bos> sanatçı , bir heykeli mermerden yapma sürecindeydi . <eos> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Değişkeni geri yükleme\n",
    "with open('train_iter.pkl', 'rb') as f:\n",
    "    train_iter = pickle.load(f)\n",
    "\n",
    "with open('en_vocab.pkl', 'rb') as f:\n",
    "    en_vocab = pickle.load(f)    \n",
    "    # Değişkeni geri yükleme\n",
    "with open('tr_vocab.pkl', 'rb') as f:\n",
    "    tr_vocab = pickle.load(f)\n",
    "    \n",
    "with open('test_iter.pkl', 'rb') as f:\n",
    "    test_iter = pickle.load(f)\n",
    "    \n",
    "with open('valid_iter.pkl', 'rb') as f:\n",
    "    valid_iter = pickle.load(f)\n",
    "    \n",
    "    \n",
    "for i, (en_id, tr_id) in enumerate(train_iter):\n",
    "    print('English:', ' '.join([en_vocab.lookup_token(idx) for idx in en_id[:, 0]]))\n",
    "    print('French:', ' '.join([tr_vocab.lookup_token(idx) for idx in tr_id[:, 0]]))\n",
    "    if i == 4: \n",
    "        break\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435eeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout_p=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, num_attention_heads, \n",
    "                 num_encoder_layers, num_decoder_layers, dim_feedforward, \n",
    "                 max_seq_length, pos_dropout, transformer_dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed_src = nn.Embedding(input_dim, d_model)\n",
    "        self.embed_tgt = nn.Embedding(output_dim, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, pos_dropout, max_seq_length)\n",
    "        \n",
    "        self.transformer = nn.Transformer(d_model, num_attention_heads, num_encoder_layers, \n",
    "                                          num_decoder_layers, dim_feedforward, transformer_dropout)\n",
    "        self.output = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "    def forward(self,\n",
    "                src=None, \n",
    "                tgt=None,\n",
    "                src_mask=None,\n",
    "                tgt_mask=None, \n",
    "                src_key_padding_mask=None, \n",
    "                tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None,\n",
    "                src_embeds=None, \n",
    "                tgt_embeds=None):\n",
    "        \n",
    "        if (src_embeds is None) and (src is not None):\n",
    "            if (tgt_embeds is None) and (tgt is not None):\n",
    "                src_embeds, tgt_embeds = self._embed_tokens(src, tgt)\n",
    "        elif (src_embeds is not None) and (src is not None):\n",
    "            raise ValueError(\"Must specify exactly one of src and src_embeds\")\n",
    "        elif (src_embeds is None) and (src is None):\n",
    "            raise ValueError(\"Must specify exactly one of src and src_embeds\")\n",
    "        elif (tgt_embeds is not None) and (tgt is not None):\n",
    "            raise ValueError(\"Must specify exactly one of tgt and tgt_embeds\")\n",
    "        elif (tgt_embeds is None) and (tgt is None):\n",
    "            raise ValueError(\"Must specify exactly one of tgt and tgt_embeds\")\n",
    "        \n",
    "        output = self.transformer(src_embeds, \n",
    "                                  tgt_embeds, \n",
    "                                  tgt_mask=tgt_mask, \n",
    "                                  src_key_padding_mask=src_key_padding_mask,\n",
    "                                  tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                                  memory_key_padding_mask=memory_key_padding_mask)\n",
    "        \n",
    "        return self.output(output)\n",
    "    \n",
    "    def _embed_tokens(self, src, tgt):\n",
    "        src_embeds = self.embed_src(src) * np.sqrt(self.d_model)\n",
    "        tgt_embeds = self.embed_tgt(tgt) * np.sqrt(self.d_model)\n",
    "        \n",
    "        src_embeds = self.pos_enc(src_embeds)\n",
    "        tgt_embeds = self.pos_enc(tgt_embeds)\n",
    "        return src_embeds, tgt_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469244d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model, iterator, optimizer, loss_fn, device, clip=None):\n",
    "    model.train()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=len(iterator), leave=False) as t:\n",
    "        for i, (src, tgt) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "            tgt_inp, tgt_out = tgt[:-1, :], tgt[1:, :]\n",
    "\n",
    "            tgt_mask = model.transformer.generate_square_subsequent_mask(tgt_inp.size(0)).to(device)\n",
    "            src_key_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "            tgt_key_padding_mask = (tgt_inp == PAD_IDX).transpose(0, 1)\n",
    "            memory_key_padding_mask = src_key_padding_mask.clone()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(src=src, tgt=tgt_inp, \n",
    "                           tgt_mask=tgt_mask,\n",
    "                           src_key_padding_mask = src_key_padding_mask,\n",
    "                           tgt_key_padding_mask = tgt_key_padding_mask,\n",
    "                           memory_key_padding_mask = memory_key_padding_mask)\n",
    "            \n",
    "            loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                           tgt_out.view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if clip is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / (i+1)\n",
    "            t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                          ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "            t.update()\n",
    "            \n",
    "    return epoch_loss / len(iterator)\n",
    "    \n",
    "def evaluate_transformer(model, iterator, loss_fn, device):\n",
    "    model.eval()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(iterator), leave=False) as t:\n",
    "            for i, (src, tgt) in enumerate(iterator):\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                \n",
    "                # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "                tgt_inp, tgt_out = tgt[:-1, :], tgt[1:, :]\n",
    "                \n",
    "                tgt_mask = model.transformer.generate_square_subsequent_mask(tgt_inp.size(0)).to(device)\n",
    "                src_key_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "                tgt_key_padding_mask = (tgt_inp == PAD_IDX).transpose(0, 1)\n",
    "                memory_key_padding_mask = src_key_padding_mask.clone()\n",
    "\n",
    "                output = model(src=src, tgt=tgt_inp, \n",
    "                               tgt_mask=tgt_mask,\n",
    "                               src_key_padding_mask = src_key_padding_mask,\n",
    "                               tgt_key_padding_mask = tgt_key_padding_mask,\n",
    "                               memory_key_padding_mask = memory_key_padding_mask)\n",
    "                \n",
    "                loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                               tgt_out.view(-1))\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                avg_loss = epoch_loss / (i+1)\n",
    "                t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                              ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "                t.update()\n",
    "    \n",
    "    return epoch_loss / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e645a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VuralBayrakli\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerModel(input_dim=len(en_vocab), \n",
    "                             output_dim=len(tr_vocab), \n",
    "                             d_model=256, \n",
    "                             num_attention_heads=8,\n",
    "                             num_encoder_layers=6, \n",
    "                             num_decoder_layers=6, \n",
    "                             dim_feedforward=2048,\n",
    "                             max_seq_length=32,\n",
    "                             pos_dropout=0.15,\n",
    "                             transformer_dropout=0.3)\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8503d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecac55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad762cf1f5d49f0856741fd116d1278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfea8de984e4f72afc6756da368ecf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VuralBayrakli\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_EPOCHS = 50\n",
    "CLIP = 15 # clipping value, or None to prevent gradient clipping\n",
    "EARLY_STOPPING_EPOCHS = 5\n",
    "SAVE_DIR = os.getcwd() \n",
    "model_path = os.path.join(SAVE_DIR, 'transformer_en_tr.pt')\n",
    "transformer_metrics = {}\n",
    "best_valid_loss = float(\"inf\")\n",
    "early_stopping_count = 0\n",
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Epoch\"):\n",
    "    train_loss = train_transformer(transformer, train_iter, xf_optim, loss_fn, device, clip=CLIP)\n",
    "    valid_loss = evaluate_transformer(transformer, valid_iter, loss_fn, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        tqdm.write(f\"Checkpointing at epoch {epoch + 1}\")\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(transformer.state_dict(), model_path)\n",
    "        early_stopping_count = 0\n",
    "    elif epoch > EARLY_STOPPING_EPOCHS:\n",
    "        early_stopping_count += 1\n",
    "    \n",
    "    transformer_metrics[epoch+1] = dict(\n",
    "        train_loss = train_loss,\n",
    "        train_ppl = np.exp(train_loss),\n",
    "        valid_loss = valid_loss,\n",
    "        valid_ppl = np.exp(valid_loss)\n",
    "    )\n",
    "    \n",
    "    if early_stopping_count == EARLY_STOPPING_EPOCHS:\n",
    "        tqdm.write(f\"Early stopping triggered in epoch {epoch + 1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748f05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
